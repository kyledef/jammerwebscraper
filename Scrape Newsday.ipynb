{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The system will provide a simple example of using python to extract information from a website. Note this is part 1 of 4. Participants are not expected to have any experience in python or background in web scraping. However, some understanding of HTML will be useful.\n",
    "\n",
    "This draws inspiration from http://web.stanford.edu/~zlotnick/TextAsData/Web_Scraping_with_Beautiful_Soup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import dependencies (i.e. packages that extend the standard language to perform specific [advance] functionality)\n",
    "import urllib\n",
    "from datetime import datetime, date, timedelta\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From analysing the newsday archieve website we see that the URL follows a parsable convention\n",
    "http://www.newsday.co.tt/archives/YYYY-M-DD.html \n",
    "So our general approach will be as follows:\n",
    "    1. Generate date in the expected form between an ending and starting date\n",
    "    2. Test to ensure the dates generated are valid. (refine step1 based on results)\n",
    "    3. Read the content and process based on our goal for scaping the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1 - create a function to generates a list(array) of dates\n",
    "def genDates(start_date = date.today(), num_days = 3):\n",
    "    # date_list = [start - timedelta(days=x) for x in range(0, num_days)] # generate a list of dates\n",
    "    # While we expand the above line for beginners understanding \n",
    "    date_list = []\n",
    "    for d in range(0, num_days):\n",
    "        temp = start_date - timedelta(days=d)\n",
    "        date_list.append(temp.strftime('%Y-%-m-%d'))# http://strftime.org/ used a reference\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2 -Test the generated URL to ensure they point to \n",
    "def traverseDates(func, start_date = date.today(), num_days = 3):\n",
    "    base_url=\"http://www.newsday.co.tt/archives/\"\n",
    "    dates_str_list = genDates(start_date, num_days)\n",
    "    for date in dates_str_list:\n",
    "        url = base_url + date\n",
    "        func(url)\n",
    "        \n",
    "def printDate(date):\n",
    "    print(date)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3 - Read content and process page\n",
    "def processPage(page_url):\n",
    "    print(\"Reading content from {0}\".format(page_url))\n",
    "    page_content = urllib.urlopen(page_url).read()\n",
    "    beau = BeautifulSoup(page_content, \"html5lib\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traverseDates(processPage,num_days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
